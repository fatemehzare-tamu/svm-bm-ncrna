{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d3b21e-6f5a-4700-b87d-ea7ae1c8bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce GTX 1050 with Max-Q Design\n",
      "CUDA OK: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"CUDA OK:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44f46d6f-72ff-477f-b369-b1b26cf74dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def myloss(model, x, y):\n",
    "    # reshape for sklearn\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "\n",
    "    # sklearn: decision_function = signed distance to hyperplane\n",
    "    score_raw = model.decision_function(x)\n",
    "\n",
    "    # For binary classification: score_raw is a scalar\n",
    "    score_abs = np.abs(score_raw)\n",
    "\n",
    "    # predicted label\n",
    "    label = model.predict(x)[0]     # scalar\n",
    "\n",
    "    # MATLAB had: score = label * abs(score)\n",
    "    score = label * score_abs\n",
    "\n",
    "    # Margin loss\n",
    "    if score * y > 1:\n",
    "        loss = 0\n",
    "    else:\n",
    "        loss = 1 - score * y\n",
    "\n",
    "    return loss, score\n",
    "\n",
    "\n",
    "def testpredicter(model, X, Y):\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    accuracy = np.mean(preds == Y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04929b3f-e171-493e-a1fa-35630522f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "def mysvmbm2(Dtrain, n2, q, N, T, l, Dtest):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------\n",
    "    # RANDOM INITIAL TRAINING SET\n",
    "    # -------------------------------\n",
    "    np.random.seed(42)\n",
    "    index = np.random.permutation(l)\n",
    "    x0 = Dtrain[index[:N], 1].reshape(-1, 1)  # first feature only\n",
    "    y0 = Dtrain[index[:N], 0]                  # labels\n",
    "\n",
    "    LAMBDA = 0.1\n",
    "    g0 = SVC(kernel='linear', C=LAMBDA)\n",
    "    g0.fit(x0, y0)\n",
    "\n",
    "    # -------------------------------\n",
    "    # ALLOCATION\n",
    "    # -------------------------------\n",
    "    gcell = [None] * T\n",
    "    alpha = np.zeros(T)\n",
    "    ACCURACY1 = np.zeros((T, 3))\n",
    "    \n",
    "    pt = [np.zeros(N + 1) for _ in range(T)]\n",
    "    Dt = [np.zeros((N, 2)) for _ in range(T)]  # column 0: label, column 1: feature\n",
    "\n",
    "    # -------------------------------\n",
    "    # INITIAL xi, yi\n",
    "    # -------------------------------\n",
    "    index = np.random.permutation(l)\n",
    "    xi = np.zeros((N+1, 1))   # only 1 feature\n",
    "    yi = np.zeros(N+1)\n",
    "    xi[0, 0] = Dtrain[index[10], 1]\n",
    "    yi[0] = Dtrain[index[10], 0]\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    # -------------------------------\n",
    "    # MAIN LOOP\n",
    "    # -------------------------------\n",
    "    while t < T:\n",
    "        i = 0\n",
    "        n1 = 0\n",
    "        flag = np.zeros(N+1)\n",
    "        COUNTER = 0\n",
    "\n",
    "        while i < N:\n",
    "            COUNTER += 1\n",
    "            index = np.random.permutation(l)\n",
    "            xstar = Dtrain[index[0], 1].reshape(1, 1)  # first feature\n",
    "            ystar = Dtrain[index[0], 0]\n",
    "\n",
    "            # COMPUTE LOSS\n",
    "            if t == 0:\n",
    "                L1, score1 = myloss(g0, xstar, ystar)\n",
    "                L2, score2 = myloss(g0, xi[i].reshape(1,1), yi[i])\n",
    "            else:\n",
    "                L1, score1 = myloss(gcell[t-1], xstar, ystar)\n",
    "                L2, score2 = myloss(gcell[t-1], xi[i].reshape(1,1), yi[i])\n",
    "\n",
    "            L1 = np.asarray(L1).item()\n",
    "            L2 = np.asarray(L2).item()\n",
    "\n",
    "            pt[t][i+1] = min(1, np.exp(-L1) / np.exp(-L2))\n",
    "\n",
    "            if n1 > n2:\n",
    "                pt[t][i+1] = min(1, q * pt[t][i+1])\n",
    "                Dt[t][i, 1] = xstar  # feature\n",
    "                Dt[t][i, 0] = ystar  # label\n",
    "                flag[i] = 1\n",
    "\n",
    "                i += 1\n",
    "                xi[i, 0] = xstar[0, 0]\n",
    "                yi[i] = ystar\n",
    "                n1 = 0\n",
    "\n",
    "            # SPECIAL CASE\n",
    "            if pt[t][i+1] == 1 and (ystar * yi[i]) == 1:\n",
    "                s1 = np.asarray(score1).item()\n",
    "                s2 = np.asarray(score2).item()\n",
    "                pt[t][i+1] = np.exp(-ystar * s1) / np.exp(-yi[i] * s2)\n",
    "\n",
    "            # ACCEPT OR REJECT\n",
    "            if np.random.rand() < pt[t][i+1]:\n",
    "                Dt[t][i, 1] = xstar[0, 0]\n",
    "                Dt[t][i, 0] = ystar\n",
    "                flag[i] = 1\n",
    "\n",
    "                i += 1\n",
    "                xi[i, 0] = xstar[0, 0]\n",
    "                yi[i] = ystar\n",
    "                n1 = 0\n",
    "\n",
    "            if flag[i] == 0:\n",
    "                n1 += 1\n",
    "\n",
    "        print(f\"Round {t+1}, COUNTER = {COUNTER}\")\n",
    "        COUNTER = 0\n",
    "\n",
    "        # -------------------------------\n",
    "        # TRAIN NEW SVM ON Dt\n",
    "        # -------------------------------\n",
    "        clf = SVC(kernel='linear', C=LAMBDA)\n",
    "        clf.fit(Dt[t][:, 1].reshape(-1,1), Dt[t][:, 0])\n",
    "        gcell[t] = clf\n",
    "\n",
    "        # -------------------------------\n",
    "        # EVALUATION\n",
    "        # -------------------------------\n",
    "        acc_train = testpredicter(clf, Dtrain[:, 1].reshape(-1,1), Dtrain[:, 0])\n",
    "        acc_Dt = testpredicter(clf, Dt[t][:, 1].reshape(-1,1), Dt[t][:, 0])\n",
    "        acc_test = testpredicter(clf, Dtest[:, 1].reshape(-1,1), Dtest[:, 0])\n",
    "\n",
    "        ACCURACY1[t, 0] = acc_Dt\n",
    "        ACCURACY1[t, 1] = acc_train\n",
    "        ACCURACY1[t, 2] = acc_test\n",
    "\n",
    "        # ALPHA\n",
    "        et = 1 - acc_train\n",
    "        alpha[t] = 0.5 * np.log((1 - et) / et)\n",
    "\n",
    "        # restart xi, yi with last sample\n",
    "        xi = np.zeros((N+1, 1))\n",
    "        yi = np.zeros(N+1)\n",
    "        xi[0, 0] = xstar[0, 0]\n",
    "        yi[0] = ystar\n",
    "\n",
    "        t += 1\n",
    "        t0 = time.time()\n",
    "\n",
    "    return gcell, alpha, ACCURACY1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b3006d86-80c7-4851-a801-c19896368daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X_train shape: (248036, 8)\n",
      "Original y_train shape: (248036,)\n",
      "Original X_test shape: (106302, 8)\n",
      "Original y_test shape: (106302,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load X arrays\n",
    "with open(\"X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open(\"X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "# Load y arrays\n",
    "with open(\"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(\"y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "\n",
    "print(\"Original X_train shape:\", X_train.shape)\n",
    "print(\"Original y_train shape:\", y_train.shape)\n",
    "print(\"Original X_test shape:\", X_test.shape)\n",
    "print(\"Original y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e6195e95-b8e4-489d-95e5-c0b4adf37bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248036, 3)\n",
      "(106302, 9)\n",
      "Round 1, COUNTER = 156\n",
      "Round 2, COUNTER = 146\n",
      "Round 3, COUNTER = 133\n",
      "Round 4, COUNTER = 161\n",
      "Round 5, COUNTER = 162\n",
      "Round 6, COUNTER = 135\n",
      "Round 7, COUNTER = 163\n",
      "Round 8, COUNTER = 175\n",
      "Round 9, COUNTER = 188\n",
      "Round 10, COUNTER = 178\n",
      "Round 1: alpha=-0.0010, Dt_acc=0.7700, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 2: alpha=-0.0010, Dt_acc=0.8000, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 3: alpha=-0.0010, Dt_acc=0.7300, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 4: alpha=-0.0010, Dt_acc=0.8100, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 5: alpha=-0.0010, Dt_acc=0.7900, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 6: alpha=-0.0010, Dt_acc=0.8100, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 7: alpha=-0.0010, Dt_acc=0.7800, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 8: alpha=-0.0010, Dt_acc=0.8600, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 9: alpha=-0.0010, Dt_acc=0.8800, Train_acc=0.4995, Test_acc=0.4067\n",
      "Round 10: alpha=-0.0010, Dt_acc=0.8900, Train_acc=0.4995, Test_acc=0.4067\n",
      "Training time (seconds): 26.817816019058228\n"
     ]
    }
   ],
   "source": [
    "N=100;\n",
    "T=10;\n",
    "n2=20;\n",
    "q=1.7;\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Combine y and X exactly like MATLAB (label first)\n",
    "#Dtrain = np.hstack([y_train_small.reshape(-1, 1), X_train_small])\n",
    "#Dtest  = np.hstack([y_test_small.reshape(-1, 1),  X_test_small])\n",
    "\n",
    "np.random.seed(42)\n",
    "flip_fraction = 0.5  # 5% label noise\n",
    "n_flip = int(flip_fraction * len(y_train))\n",
    "\n",
    "# choose indices to flip\n",
    "flip_idx = np.random.choice(len(y_train), n_flip, replace=False)\n",
    "\n",
    "# flip labels (-1 → 1, 1 → -1)\n",
    "y_train = y_train.copy()\n",
    "y_train[flip_idx] *= -1\n",
    "\n",
    "\n",
    "\n",
    "# Nonlinear combination of existing features (e.g., square + sin)\n",
    "nonlinear_feat = X_train[:, 0]**2 + np.sin(X_train[:, 0])\n",
    "nonlinear_feat = nonlinear_feat.reshape(-1, 1)\n",
    "\n",
    "# Random irrelevant feature\n",
    "np.random.seed(42)\n",
    "random_feat = np.random.randn(X_train.shape[0], 1)\n",
    "\n",
    "# Append to training data\n",
    "X_train = np.hstack([nonlinear_feat, random_feat])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dtrain = np.hstack([y_train.reshape(-1, 1), X_train])\n",
    "Dtest  = np.hstack([y_test.reshape(-1, 1),  X_test])\n",
    "\n",
    "l = len(Dtrain)    # number of train samples\n",
    "print(Dtrain.shape)\n",
    "print(Dtest.shape)\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gcell, alpha, ACCURACY1 = mysvmbm2(Dtrain, n2, q, N, T, l, Dtest)\n",
    "\n",
    "# Accuracy per iteration\n",
    "for t in range(T):\n",
    "    print(f\"Round {t+1}: alpha={alpha[t]:.4f}, \"\n",
    "          f\"Dt_acc={ACCURACY1[t,0]:.4f}, \"\n",
    "          f\"Train_acc={ACCURACY1[t,1]:.4f}, \"\n",
    "          f\"Test_acc={ACCURACY1[t,2]:.4f}\")\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Training time (seconds):\", t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "514f33c6-3ef9-496e-92f0-027eb83fa0b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.07860617 -1.26803837 -2.02780067 ... -0.35814341  0.06950722\n -1.07696043].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 36\u001b[0m\n\u001b[0;32m     31\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(labelfinal \u001b[38;5;241m==\u001b[39m Y)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, labelfinal\n\u001b[1;32m---> 36\u001b[0m accuracy, labelfinal \u001b[38;5;241m=\u001b[39m findaccuracy4_fast(Dtest[:, \u001b[38;5;241m1\u001b[39m], Dtest[:, \u001b[38;5;241m0\u001b[39m], gcell, alpha)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[81], line 22\u001b[0m, in \u001b[0;36mfindaccuracy4_fast\u001b[1;34m(X, Y, gcell, alpha)\u001b[0m\n\u001b[0;32m     19\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gcell)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get all predictions from all T models: shape (T, num_samples)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([model\u001b[38;5;241m.\u001b[39mpredict(X) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m gcell])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Weighted vote along models\u001b[39;00m\n\u001b[0;32m     25\u001b[0m weighted_votes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(alpha, all_preds)  \u001b[38;5;66;03m# shape (num_samples,)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:822\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    820\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:436\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    437\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:614\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    611\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m--> 614\u001b[0m     X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    616\u001b[0m         X,\n\u001b[0;32m    617\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    618\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    619\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    620\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    621\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    622\u001b[0m     )\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m    625\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1092\u001b[0m             )\n\u001b[1;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.07860617 -1.26803837 -2.02780067 ... -0.35814341  0.06950722\n -1.07696043].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def findaccuracy4_fast(X, Y, gcell, alpha):\n",
    "    \"\"\"\n",
    "    Vectorized ensemble prediction with weighted SVMs.\n",
    "\n",
    "    Parameters:\n",
    "    X      : features (num_samples x num_features)\n",
    "    Y      : labels (num_samples,)\n",
    "    gcell  : list of trained SVMs (length T)\n",
    "    alpha  : weights for each SVM (length T)\n",
    "\n",
    "    Returns:\n",
    "    accuracy    : float\n",
    "    labelfinal  : array of predicted labels\n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    T = len(gcell)\n",
    "\n",
    "    # Get all predictions from all T models: shape (T, num_samples)\n",
    "    all_preds = np.array([model.predict(X) for model in gcell])\n",
    "\n",
    "    # Weighted vote along models\n",
    "    weighted_votes = np.dot(alpha, all_preds)  # shape (num_samples,)\n",
    "\n",
    "    # Final predicted labels\n",
    "    labelfinal = np.sign(weighted_votes)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = np.mean(labelfinal == Y)\n",
    "\n",
    "    return accuracy, labelfinal\n",
    "\n",
    "\n",
    "accuracy, labelfinal = findaccuracy4_fast(Dtest[:, 1], Dtest[:, 0], gcell, alpha)\n",
    "print(f\"Ensemble Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "394c79c6-d68a-4bb1-a40e-1299104b9956",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'findaccuracy4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy, labelfinal \u001b[38;5;241m=\u001b[39m findaccuracy4(Dtest[:, \u001b[38;5;241m1\u001b[39m], Dtest[:, \u001b[38;5;241m0\u001b[39m], gcell, alpha, T)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'findaccuracy4' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy, labelfinal = findaccuracy4(Dtest[:, 1], Dtest[:, 0], gcell, alpha, T)\n",
    "print(f\"Ensemble Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cb45a-00ff-48ee-a4d8-823208260e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fb415-a1b1-40ee-be6d-bc660c99b508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c59a469-014b-4967-80c6-096c181ca809",
   "metadata": {},
   "source": [
    "# Simple SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "38418e8f-8d89-46fc-8870-a234ada7501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X_train shape: (248036, 8)\n",
      "Original y_train shape: (248036,)\n",
      "Original X_test shape: (106302, 8)\n",
      "Original y_test shape: (106302,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load X arrays\n",
    "with open(\"X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open(\"X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "# Load y arrays\n",
    "with open(\"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(\"y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "\n",
    "print(\"Original X_train shape:\", X_train.shape)\n",
    "print(\"Original y_train shape:\", y_train.shape)\n",
    "print(\"Original X_test shape:\", X_test.shape)\n",
    "print(\"Original y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a49a2e30-227d-4e44-9ed2-fed21972c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (1000,) (106302, 2) (106302,)\n",
      "Train Class -1: 500 samples\n",
      "Train Class 1: 500 samples\n",
      "Test Class -1: 63072 samples\n",
      "Test Class 1: 43230 samples\n",
      "Original X_train shape: (1000, 2)\n",
      "Original y_train shape: (1000,)\n",
      "Original X_test shape: (106302, 2)\n",
      "Original y_test shape: (106302,)\n",
      "Training time (seconds): 0.03617262840270996\n",
      "Train Accuracy: 0.499\n",
      "Test Accuracy: 0.4525032454704521\n",
      "\n",
      "Confusion Matrix (Train):\n",
      " [[127 373]\n",
      " [128 372]]\n",
      "\n",
      "Confusion Matrix (Test):\n",
      " [[15079 47993]\n",
      " [10207 33023]]\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.24      0.34     63072\n",
      "           1       0.41      0.76      0.53     43230\n",
      "\n",
      "    accuracy                           0.45    106302\n",
      "   macro avg       0.50      0.50      0.44    106302\n",
      "weighted avg       0.52      0.45      0.42    106302\n",
      "\n",
      "(1000, 3)\n",
      "(106302, 3)\n",
      "Training time (seconds): 0.04252266883850098\n",
      "Training time (seconds): 0.1419816017150879\n",
      "Training time (seconds): 0.27467799186706543\n",
      "Training time (seconds): 0.3898146152496338\n",
      "Training time (seconds): 0.5112559795379639\n",
      "Training time (seconds): 0.6347661018371582\n",
      "Training time (seconds): 0.7518086433410645\n",
      "Training time (seconds): 0.8760330677032471\n",
      "Training time (seconds): 0.058356523513793945\n",
      "Training time (seconds): 0.06284594535827637\n",
      "Training time (seconds): 0.19561529159545898\n",
      "Training time (seconds): 0.3168156147003174\n",
      "Training time (seconds): 0.4507770538330078\n",
      "Training time (seconds): 0.5743246078491211\n",
      "Training time (seconds): 0.6972005367279053\n",
      "Training time (seconds): 0.842573881149292\n",
      "Training time (seconds): 0.9730970859527588\n",
      "Training time (seconds): 1.0921907424926758\n",
      "Training time (seconds): 1.2128140926361084\n",
      "Training time (seconds): 1.342484951019287\n",
      "Training time (seconds): 0.043711185455322266\n",
      "Training time (seconds): 0.1737673282623291\n",
      "Training time (seconds): 0.04024076461791992\n",
      "Training time (seconds): 0.03185534477233887\n",
      "Training time (seconds): 0.03302621841430664\n",
      "Training time (seconds): 0.03868913650512695\n",
      "Training time (seconds): 0.16565752029418945\n",
      "Training time (seconds): 0.2776913642883301\n",
      "Training time (seconds): 0.05525350570678711\n",
      "Training time (seconds): 0.15754294395446777\n",
      "Training time (seconds): 0.277313232421875\n",
      "Training time (seconds): 0.031735897064208984\n",
      "Training time (seconds): 0.17050647735595703\n",
      "Training time (seconds): 0.27125120162963867\n",
      "Training time (seconds): 0.4018712043762207\n",
      "Round 1: alpha=0.0080, Dt_acc=0.7000, Train_acc=0.5040, Test_acc=0.4552\n",
      "Round 2: alpha=0.0140, Dt_acc=0.6000, Train_acc=0.5070, Test_acc=0.3997\n",
      "Round 3: alpha=0.0060, Dt_acc=0.7000, Train_acc=0.5030, Test_acc=0.4537\n",
      "Round 4: alpha=0.0100, Dt_acc=0.7000, Train_acc=0.5050, Test_acc=0.4547\n",
      "Round 5: alpha=0.0080, Dt_acc=0.8000, Train_acc=0.5040, Test_acc=0.4547\n",
      "Round 6: alpha=0.0040, Dt_acc=0.7000, Train_acc=0.5020, Test_acc=0.4620\n",
      "Round 7: alpha=0.0080, Dt_acc=0.6000, Train_acc=0.5040, Test_acc=0.4543\n",
      "Round 8: alpha=0.0040, Dt_acc=0.9000, Train_acc=0.5020, Test_acc=0.4736\n",
      "Round 9: alpha=0.0160, Dt_acc=0.6000, Train_acc=0.5080, Test_acc=0.4054\n",
      "Round 10: alpha=0.0180, Dt_acc=0.6000, Train_acc=0.5090, Test_acc=0.4625\n",
      "Training time (seconds): 4.44634222984314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)  # fix seed\n",
    "noise_level = 0.1\n",
    "X_train = X_train + noise_level * np.random.randn(*X_train.shape)\n",
    "\n",
    "\n",
    "np.random.seed(21)  # fix seed\n",
    "noise_level = 0.1\n",
    "X_test = X_test  + noise_level * np.random.randn(*X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "flip_fraction = 0.5  # 5% label noise\n",
    "n_flip = int(flip_fraction * len(y_train))\n",
    "\n",
    "# choose indices to flip\n",
    "flip_idx = np.random.choice(len(y_train), n_flip, replace=False)\n",
    "\n",
    "# flip labels (-1 → 1, 1 → -1)\n",
    "y_train = y_train.copy()\n",
    "y_train[flip_idx] *= -1\n",
    "\n",
    "\n",
    "\n",
    "# Nonlinear combination of existing features (e.g., square + sin)\n",
    "nonlinear_feat = X_train[:, 0]**2 + np.sin(X_train[:, 0])\n",
    "nonlinear_feat = nonlinear_feat.reshape(-1, 1)\n",
    "\n",
    "# Random irrelevant feature\n",
    "np.random.seed(42)\n",
    "random_feat = np.random.randn(X_train.shape[0], 1)\n",
    "\n",
    "# Append to training data\n",
    "X_train = np.hstack([nonlinear_feat, random_feat])\n",
    "\n",
    "\n",
    "\n",
    "nonlinear_feat_test = X_test[:, 0]**2 + np.sin(X_test[:, 0])\n",
    "nonlinear_feat_test = nonlinear_feat_test.reshape(-1, 1)\n",
    "\n",
    "np.random.seed(42)\n",
    "random_feat_test = np.random.randn(X_test.shape[0], 1)\n",
    "\n",
    "X_test = np.hstack([nonlinear_feat_test, random_feat_test])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#X_train = X_train[:, :2]   # columns 0 and 1\n",
    "#X_test  = X_test[:, :2]\n",
    "np.random.seed(42)\n",
    "index = np.random.permutation(100)\n",
    "#x0 = Dtrain[index[:N], 1].reshape(-1, 1)  # first feature only\n",
    "#y0 = Dtrain[index[:N], 0]                  # labels\n",
    "\n",
    "\n",
    "# Find indices of each class in the full training set\n",
    "idx_pos = np.where(y_train == 1)[0]      # class 1\n",
    "idx_neg = np.where(y_train == -1)[0]     # class -1\n",
    "\n",
    "# Randomly choose 50 from each\n",
    "np.random.seed(42)\n",
    "sel_pos = np.random.choice(idx_pos, 500, replace=False)\n",
    "sel_neg = np.random.choice(idx_neg, 500, replace=False)\n",
    "\n",
    "# Combine indices\n",
    "selected_idx = np.concatenate([sel_pos, sel_neg])\n",
    "np.random.shuffle(selected_idx)\n",
    "\n",
    "# Extract the balanced training subset\n",
    "X_train= X_train[selected_idx,0:4]\n",
    "y_train = y_train[selected_idx]\n",
    "\n",
    "#print(X_train.shape, y_train.shape)\n",
    "#print(\"Class -1:\", np.sum(y_train == -1))\n",
    "#print(\"Class 1 :\", np.sum(y_train == 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#X_train = X_train [index, 0:1] \n",
    "#y_train = y_train  [index] \n",
    "X_test = X_test [:, 0:4] \n",
    "y_test = y_test\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "for c, cnt in zip(classes, counts):\n",
    "    print(f\"Train Class {c}: {cnt} samples\")\n",
    "\n",
    "classes, counts = np.unique(y_test, return_counts=True)\n",
    "for c, cnt in zip(classes, counts):\n",
    "    print(f\"Test Class {c}: {cnt} samples\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original X_train shape:\", X_train.shape)\n",
    "print(\"Original y_train shape:\", y_train.shape)\n",
    "print(\"Original X_test shape:\", X_test.shape)\n",
    "print(\"Original y_test shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "\n",
    "#svm_sgd = SGDClassifier(loss=\"hinge\", max_iter=1000, verbose=1)\n",
    "#svm_sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# SVM model (you can tune later)\n",
    "\n",
    "#svm = LinearSVC(C=0.1, max_iter=10000)\n",
    "svm = SVC(kernel='linear', C=0.1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Training time (seconds):\", t1 - t0)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test  = svm.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "cm_test  = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nConfusion Matrix (Train):\\n\", cm_train)\n",
    "print(\"\\nConfusion Matrix (Test):\\n\", cm_test)\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dtrain = np.hstack([y_train.reshape(-1, 1), X_train])\n",
    "Dtest  = np.hstack([y_test.reshape(-1, 1),  X_test])\n",
    "\n",
    "l = len(Dtrain)    # number of train samples\n",
    "print(Dtrain.shape)\n",
    "print(Dtest.shape)\n",
    "\n",
    "# Train\n",
    "\n",
    "\n",
    "N=10;\n",
    "T=10;\n",
    "n2=20;\n",
    "q=1.7;\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "gcell, alpha, ACCURACY1 = mysvmbm3(Dtrain, n2, q, N, T, l, Dtest,2)\n",
    "\n",
    "#gcell, alpha, ACCURACY1 = mysvmbm(Dtrain, n2, q, N, T, l, Dtest)\n",
    "\n",
    "# Accuracy per iteration\n",
    "for t in range(T):\n",
    "    print(f\"Round {t+1}: alpha={alpha[t]:.4f}, \"\n",
    "          f\"Dt_acc={ACCURACY1[t,0]:.4f}, \"\n",
    "          f\"Train_acc={ACCURACY1[t,1]:.4f}, \"\n",
    "          f\"Test_acc={ACCURACY1[t,2]:.4f}\")\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Training time (seconds):\", t1 - t0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b2a585ad-bf93-4614-b6da-b30cf73062f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Mover's Distance: 0.0684737393962939\n",
      "KS Statistic: 0.02702197512746707 p-value: 0.45640173974560583\n",
      "Train mean: 0.48055457043056793\n",
      "Test mean: 0.5052389614679321\n",
      "Train std: 1.358775984807308\n",
      "Test std: 1.4053351730196078\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 1 has size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[257], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 23\u001b[0m corr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcorrcoef(X_train[:, \u001b[38;5;241m0\u001b[39m], X_test[:\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrelation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, corr)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2889\u001b[0m, in \u001b[0;36mcorrcoef\u001b[1;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[0;32m   2885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[0;32m   2886\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[0;32m   2887\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2888\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2889\u001b[0m c \u001b[38;5;241m=\u001b[39m cov(x, y, rowvar, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2891\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2683\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rowvar \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2682\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 2683\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((X, y), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 1 has size 100"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance, ks_2samp\n",
    "\n",
    "# Earth Mover’s Distance\n",
    "emd = wasserstein_distance(X_train[:, 0], X_test[:, 0])\n",
    "\n",
    "# Kolmogorov–Smirnov test\n",
    "ks_stat, ks_pvalue = ks_2samp(X_train[:, 0], X_test[:, 0])\n",
    "\n",
    "print(\"Earth Mover's Distance:\", emd)\n",
    "print(\"KS Statistic:\", ks_stat, \"p-value:\", ks_pvalue)\n",
    "print(\"Train mean:\", np.mean(X_train))\n",
    "print(\"Test mean:\", np.mean(X_test))\n",
    "\n",
    "print(\"Train std:\", np.std(X_train))\n",
    "print(\"Test std:\", np.std(X_test))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(X_train[:,0], bins=50, alpha=0.5, label=\"Train\", density=True)\n",
    "plt.hist(X_test[:,0], bins=50, alpha=0.5, label=\"Test\", density=True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "corr = np.corrcoef(X_train[:, 0], X_test[:100, 0])[0,1]\n",
    "print(\"Correlation:\", corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c8b84a78-4175-4b56-befe-e4a03683a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def mysvmbm(Dtrain, n2, q, N, T, l, Dtest):\n",
    "    t0 = time.time()\n",
    "    # -------------------------------------\n",
    "    #  RANDOM INITIAL TRAINING SET\n",
    "    # -------------------------------------\n",
    "    index = np.random.permutation(l)\n",
    "    x0 = Dtrain[index[:N], 1:9]   # columns 2:9 \n",
    "    y0 = Dtrain[index[:N], 0]     # column 1\n",
    "    \n",
    "    LAMBDA = 0.1\n",
    "    g0 = SVC(kernel='linear', C=LAMBDA)\n",
    "    g0.fit(x0, y0)\n",
    "\n",
    "    # -------------------------------------\n",
    "    #  ALLOCATION\n",
    "    # -------------------------------------\n",
    "    gcell = [None] * T\n",
    "    alpha = np.zeros(T)\n",
    "    ACCURACY1 = np.zeros((T, 3))\n",
    "    \n",
    "    pt = [np.zeros(N + 1) for _ in range(T)]\n",
    "    Dt = [np.zeros((N, 9)) for _ in range(T)]\n",
    "\n",
    "    # -------------------------------------\n",
    "    #  INITIAL xi , yi\n",
    "    # -------------------------------------\n",
    "    index = np.random.permutation(l)\n",
    "    xi = np.zeros((N+1, 8))\n",
    "    yi = np.zeros(N+1)\n",
    "\n",
    "    xi[0, :] = Dtrain[index[10], 1:9]\n",
    "    yi[0] = Dtrain[index[10], 0]\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # MAIN LOOP  t = 1 ... T\n",
    "    # ---------------------------------------------------\n",
    "    while t < T:\n",
    "\n",
    "        i = 0\n",
    "        n1 = 0\n",
    "        flag = np.zeros(N+1)\n",
    "        COUNTER=0;\n",
    "\n",
    "        while i < N:\n",
    "            COUNTER=COUNTER+1\n",
    "            index = np.random.permutation(l)\n",
    "            xstar = Dtrain[index[0], 1:9]\n",
    "            ystar = Dtrain[index[0], 0]\n",
    "\n",
    "            # ---------------------------------------------\n",
    "            # COMPUTE LOSS\n",
    "            # ---------------------------------------------\n",
    "            if t == 0:\n",
    "                L1, score1 = myloss(g0, xstar, ystar)\n",
    "                L2, score2 = myloss(g0, xi[i], yi[i])\n",
    "            else:\n",
    "                L1, score1 = myloss(gcell[t-1], xstar, ystar)\n",
    "                L2, score2 = myloss(gcell[t-1], xi[i], yi[i])\n",
    "\n",
    "            # ---------------------------------------------\n",
    "            # UPDATE pt\n",
    "            # ---------------------------------------------\n",
    "            L1 = np.asarray(L1).item()\n",
    "            L2 = np.asarray(L2).item()\n",
    "\n",
    "            pt[t][i+1] = min(1, np.exp(-L1) / np.exp(-L2))\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            #pt[t][i+1] = min(1, np.exp(-L1) / np.exp(-L2))\n",
    "\n",
    "            if n1 > n2:\n",
    "                pt[t][i+1] = min(1, q * pt[t][i+1])\n",
    "                Dt[t][i, 1:9] = xstar\n",
    "                Dt[t][i, 0] = ystar\n",
    "                flag[i] = 1\n",
    "\n",
    "                i += 1\n",
    "                xi[i] = xstar\n",
    "                yi[i] = ystar\n",
    "                n1 = 0\n",
    "\n",
    "            # ---------------------------------------------\n",
    "            # SPECIAL CASE\n",
    "            # ---------------------------------------------\n",
    "            if pt[t][i+1] == 1 and (ystar * yi[i]) == 1:\n",
    "                #pt[t][i+1] = np.exp(-ystar * score1) / np.exp(-yi[i] * score2)\n",
    "                #pt[t][i+1] = np.exp(-ystar * float(score1)) / np.exp(-yi[i] * float(score2))\n",
    "                s1 = np.asarray(score1).item()\n",
    "                s2 = np.asarray(score2).item()\n",
    "                \n",
    "                pt[t][i+1] = np.exp(-ystar * s1) / np.exp(-yi[i] * s2)\n",
    "\n",
    "\n",
    "\n",
    "            # ---------------------------------------------\n",
    "            # ACCEPT OR REJECT\n",
    "            # ---------------------------------------------\n",
    "            if np.random.rand() < pt[t][i+1]:\n",
    "                Dt[t][i, 1:9] = xstar\n",
    "                Dt[t][i, 0] = ystar\n",
    "                flag[i] = 1\n",
    "\n",
    "                i += 1\n",
    "                xi[i] = xstar\n",
    "                yi[i] = ystar\n",
    "                n1 = 0\n",
    "\n",
    "            if flag[i] == 0:\n",
    "                n1 += 1\n",
    "\n",
    "\n",
    "        print(COUNTER)\n",
    "        COUNTER=0\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # END WHILE i\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # TRAIN NEW SVM ON Dt\n",
    "        # ----------------------------------------------------\n",
    "        clf = SVC(kernel='linear', C=LAMBDA)\n",
    "        print(Dt[t].shape)\n",
    "        clf.fit(Dt[t][:, 1:9], Dt[t][:, 0])\n",
    "        gcell[t] = clf\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # EVALUATION\n",
    "        # ----------------------------------------------------\n",
    "        acc_train = testpredicter(clf, Dtrain[:, 1:9], Dtrain[:, 0])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # compute alpha\n",
    "        et = 1 - acc_train\n",
    "        #alpha = 0.5 * np.log((1 - et) / et)\n",
    "        alpha[t] = 0.5 * np.log((1 - et) / et)\n",
    "\n",
    "        # restart xi, yi with last sample\n",
    "        xi = np.zeros((N+1, 8))\n",
    "        yi = np.zeros(N+1)\n",
    "        xi[0, :] = xstar\n",
    "        yi[0] = ystar\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(\"Training time (seconds):\", t1 - t0)\n",
    "\n",
    "        acc_Dt = testpredicter(clf, Dt[t][:, 1:9], Dt[t][:, 0])\n",
    "        acc_test = testpredicter(clf, Dtest[:, 1:9], Dtest[:, 0])\n",
    "        ACCURACY1[t, 0] = acc_Dt      # accuracy on Dt\n",
    "        ACCURACY1[t, 1] = acc_train   # accuracy on Dtrain\n",
    "        ACCURACY1[t, 2] = acc_test    # accuracy on Dtest\n",
    "\n",
    "        if alpha[t] > 0:\n",
    "            t += 1\n",
    "            t0 = time.time()\n",
    "\n",
    "    \n",
    "\n",
    "    return gcell, alpha, ACCURACY1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "67fb7456-9bc9-47f5-810b-c7479a593c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "def mysvmbm3(Dtrain, n2, q, N, T, l, Dtest, n_features=None):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Determine number of features dynamically\n",
    "    if n_features is None:\n",
    "        n_features = Dtrain.shape[1] - 1   # first column is label\n",
    "\n",
    "    # -------------------------------------\n",
    "    #  RANDOM INITIAL TRAINING SET\n",
    "    # -------------------------------------\n",
    "    index = np.random.permutation(l)\n",
    "    x0 = Dtrain[index[:N], 1:n_features+1]   # flexible feature slice\n",
    "    y0 = Dtrain[index[:N], 0]               # labels in column 0\n",
    "    \n",
    "    LAMBDA = 0.1\n",
    "    g0 = SVC(kernel='linear', C=LAMBDA)\n",
    "    g0.fit(x0, y0)\n",
    "\n",
    "    # -------------------------------------\n",
    "    #  ALLOCATION\n",
    "    # -------------------------------------\n",
    "    gcell = [None] * T\n",
    "    alpha = np.zeros(T)\n",
    "    ACCURACY1 = np.zeros((T, 3))\n",
    "    \n",
    "    pt = [np.zeros(N + 1) for _ in range(T)]\n",
    "    Dt = [np.zeros((N, n_features+1)) for _ in range(T)]\n",
    "\n",
    "    # -------------------------------------\n",
    "    #  INITIAL xi , yi\n",
    "    # -------------------------------------\n",
    "    index = np.random.permutation(l)\n",
    "    xi = np.zeros((N+1, n_features))\n",
    "    yi = np.zeros(N+1)\n",
    "\n",
    "    xi[0, :] = Dtrain[index[10], 1:n_features+1]\n",
    "    yi[0] = Dtrain[index[10], 0]\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # MAIN LOOP  t = 1 ... T\n",
    "    # ---------------------------------------------------\n",
    "    while t < T:\n",
    "\n",
    "        i = 0\n",
    "        n1 = 0\n",
    "        flag = np.zeros(N+1)\n",
    "        COUNTER=0\n",
    "\n",
    "        while i < N:\n",
    "            COUNTER += 1\n",
    "            index = np.random.permutation(l)\n",
    "            xstar = Dtrain[index[0], 1:n_features+1]\n",
    "            ystar = Dtrain[index[0], 0]\n",
    "\n",
    "            # ---------------------------------------------\n",
    "            # COMPUTE LOSS\n",
    "            # ---------------------------------------------\n",
    "            if t == 0:\n",
    "                L1, score1 = myloss(g0, xstar, ystar)\n",
    "                L2, score2 = myloss(g0, xi[i], yi[i])\n",
    "            else:\n",
    "                L1, score1 = myloss(gcell[t-1], xstar, ystar)\n",
    "                L2, score2 = myloss(gcell[t-1], xi[i], yi[i])\n",
    "\n",
    "            L1 = np.asarray(L1).item()\n",
    "            L2 = np.asarray(L2).item()\n",
    "\n",
    "            pt[t][i+1] = min(1, np.exp(-L1) / np.exp(-L2))\n",
    "\n",
    "            if n1 > n2:\n",
    "                pt[t][i+1] = min(1, q * pt[t][i+1])\n",
    "                Dt[t][i, 1:n_features+1] = xstar\n",
    "                Dt[t][i, 0] = ystar\n",
    "                flag[i] = 1\n",
    "                i += 1\n",
    "                xi[i] = xstar\n",
    "                yi[i] = ystar\n",
    "                n1 = 0\n",
    "\n",
    "            # SPECIAL CASE\n",
    "            if pt[t][i+1] == 1 and (ystar * yi[i]) == 1:\n",
    "                s1 = np.asarray(score1).item()\n",
    "                s2 = np.asarray(score2).item()\n",
    "                pt[t][i+1] = np.exp(-ystar * s1) / np.exp(-yi[i] * s2)\n",
    "\n",
    "            # ACCEPT OR REJECT\n",
    "            if np.random.rand() < pt[t][i+1]:\n",
    "                Dt[t][i, 1:n_features+1] = xstar\n",
    "                Dt[t][i, 0] = ystar\n",
    "                flag[i] = 1\n",
    "                i += 1\n",
    "                xi[i] = xstar\n",
    "                yi[i] = ystar\n",
    "                n1 = 0\n",
    "\n",
    "            if flag[i] == 0:\n",
    "                n1 += 1\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # TRAIN NEW SVM ON Dt\n",
    "        # ----------------------------------------------------\n",
    "        clf = SVC(kernel='linear', C=LAMBDA)\n",
    "        clf.fit(Dt[t][:, 1:n_features+1], Dt[t][:, 0])\n",
    "        gcell[t] = clf\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # EVALUATION\n",
    "        # ----------------------------------------------------\n",
    "        acc_train = testpredicter(clf, Dtrain[:, 1:n_features+1], Dtrain[:, 0])\n",
    "        et = 1 - acc_train\n",
    "        alpha[t] = 0.5 * np.log((1 - et) / et)\n",
    "\n",
    "        # restart xi, yi with last sample\n",
    "        xi = np.zeros((N+1, n_features))\n",
    "        yi = np.zeros(N+1)\n",
    "        xi[0, :] = xstar\n",
    "        yi[0] = ystar\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(\"Training time (seconds):\", t1 - t0)\n",
    "\n",
    "        acc_Dt = testpredicter(clf, Dt[t][:, 1:n_features+1], Dt[t][:, 0])\n",
    "        acc_test = testpredicter(clf, Dtest[:, 1:n_features+1], Dtest[:, 0])\n",
    "        ACCURACY1[t, 0] = acc_Dt\n",
    "        ACCURACY1[t, 1] = acc_train\n",
    "        ACCURACY1[t, 2] = acc_test\n",
    "\n",
    "        if alpha[t] > 0:\n",
    "            t += 1\n",
    "            t0 = time.time()\n",
    "\n",
    "    return gcell, alpha, ACCURACY1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82fd5d-e7bd-4bec-a4cc-ba09b20b853b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
